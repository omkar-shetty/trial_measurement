---
title: "Binary Trial Design"
output: html_notebook
---

Testing a few approaches to compare and contrast different methodologies for trials with a binary outcome (success/failure trials).

```{r, echo=FALSE}

library(data.table)
library(oddsratio)
library(ggplot2)

```



```{r}

# Defining trial parameters

trial_config <- list(
  groups = LETTERS[1:2],
  time_units = 30,
  group_a = 0.8,
  group_b = 0.9,
  n = 100
)

```

FOr this toy example, lets assume that a retail chain has a new process to improve on-shelf availability of products.
One way of testing if the new process is significantly better is by trialling two different groups - one with the new process and the control group with the regular process.

The questions that we want to answer are :
* Is the new process *significantly* better than the original ?
* If yes, what is the difference between the groups ?
* Is the trial enough for us to arrive at a conclusion ?

## Generating Simulated Trial Data

```{r}

trial_data <- data.table(
  GROUP = rep(trial_config$groups, each = trial_config$time_units * trial_config$n),
  TIME = rep(1:trial_config$time_units, each = trial_config$n * length(trial_config$groups)),
  OUTCOME = c(rbinom(n = trial_config$n * trial_config$time_units, size = 1, prob = trial_config$group_a),rbinom(n = trial_config$n * trial_config$time_units, size = 1, prob = trial_config$group_b))
)

```

## Confusion Matrix of the outcome

```{r}
table(trial_data$GROUP, trial_data$OUTCOME)
```

The odds ratio here is (2722/278) / (2378/622) = 2.56 which implies a positive effect for group B (as the odds ratio > 1) 

Also Visualizing the split

```{r}
ggplot(trial_data) +
  aes(x = GROUP, fill = as.factor(OUTCOME)) +
  geom_bar(position = "fill") +
  theme_bw() +
  labs(fill = 'Outcome')
```


```{r}
#Using a logistic regression

fit1 <- glm(formula = 'OUTCOME ~ GROUP', family = binomial, data = trial_data)

```
Calculating the confidence Intreval

```{r}
or_glm(data = trial_data, model = fit1)
```

```{r}
chisq.test(table(trial_data$GROUP, trial_data$OUTCOME))

```


Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.
